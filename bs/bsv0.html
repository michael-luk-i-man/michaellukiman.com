<!--BRAIN STATES-->
<!DOCTYPE HTML>
<html>
	<head>
		<title> The State of Neuro | m. lukiman </title>
		<link rel="stylesheet" type="text/css" href="../cssx/home.css">
	</head>
	<body>

		<div id="grad" style="height:240vw;">
						<div class="sky-gradient sky-gradient-00"></div>
			<div class="sky-gradient sky-gradient-01"></div>
			<div class="sky-gradient sky-gradient-02"></div>
			<div class="sky-gradient sky-gradient-03"></div>
			<div class="sky-gradient sky-gradient-04"></div>
			<div class="sky-gradient sky-gradient-05"></div>
			<div class="sky-gradient sky-gradient-06"></div>
			<div class="sky-gradient sky-gradient-07"></div>
			<div class="sky-gradient sky-gradient-08"></div>
			<div class="sky-gradient sky-gradient-09"></div>
			<div class="sky-gradient sky-gradient-10"></div>
			<div class="sky-gradient sky-gradient-11"></div>
			<div class="sky-gradient sky-gradient-12"></div>
			<div class="sky-gradient sky-gradient-13"></div>
			<div class="sky-gradient sky-gradient-14"></div>
			<div class="sky-gradient sky-gradient-15"></div>
			<div class="sky-gradient sky-gradient-16"></div>
			<div class="sky-gradient sky-gradient-17"></div>
			<div class="sky-gradient sky-gradient-18"></div>
			<div class="sky-gradient sky-gradient-19"></div>
			<div class="sky-gradient sky-gradient-20"></div>
			<div class="sky-gradient sky-gradient-21"></div>
			<div class="sky-gradient sky-gradient-22"></div>
			<div class="sky-gradient sky-gradient-23"></div>
			<div class="sky-gradient sky-gradient-24"></div>
		</div>

		<div id="container">

			<div id="intro">
				<h1>Br<span style="color:salmon;   -webkit-text-stroke-width: 1px;
				-webkit-text-stroke-color: salmon;"></span>ain States.</h1>
				<p>by ML</p>
				<h2 style="color:black">Keeping up with cortices on cortices,<br>other species, core theses, more releases,<br>and things that please us. Sweet Yeezus.</h2>
			</div>

				<!-- <h1>At the Leading Front of Neuroscience: A Bibliometric Study of the 100 Most-Cited Articles</h1>
				<h2>Frontiers in Human Neuroscience.<br>Andy Yeung, Tazuko Goto, and W. Leung.<br> 21 July 2017. </h2> -->




			<div id="completed">
				<ul>
					<li>
						<h1>Melatonin Effects on Behavior: Possible
						Mediation by the Central GABAergic System</h1>
						<h2>Neuroscience and Behavioral Reviews.<br>A. Golombek et al.<br>1996</h2>
						<p>I've just done a writeup on the effects of caffeine, motivated by the fact that so many people use it on a daily basis without knowing its primitive effects, which is fine, but something that I wanted to really look at from a critical perspective. Next, I would want to look at the counterbalancing force in many people's universes: melatonin. While caffeine ramps you up, some people pop melatonin pills to get to sleep. I maintain my same point that I think the brain has had enough time to evolve to possess a pretty good energy maintenance system so as to not require caffeine or melatonin additives (I'm not saying the brain is perfect, but I'm saying we should get to know it for things as simple as wake and sleep cycles). So, let's see how pure melatonin influences behavior.  </p><p>From a study of acute effects: "low doses of melatonin (0.3 or 1.0mg) given at 6pm and 8pm significantly reduced the latency to sleep". Low doses seem to be the healthy approach to helping to time sleep without affecting "sleep architecture" and the next day's mood. Interestingly, a 1mg dose at 9pm actually had some subjects fall asleep slower. 6pm seems to be the best time to take melatonin. Looking on Amazon, its outrageous that the best seller has 10mg capsules, when the study referred to 0.3 to 1mg capsules. Yeah, I bet that would put people to sleep...overkill for a lot.</p><p>October 31 for October 30? Bobst</p>
						</li>
					<li>
							<h1>Actions of Caffeine in the Brain with Special Reference to Factors That Contribute to Its Widespread Use</h1>
							<h2>Pharmalogical Reviews.<br>Fredholm et al.<br>1999.</h2>
							<p>This week and last week were both midterm weeks. As a matter of fact, I have just finished taking a midterm today, and afterwards went to a happy hour for the Future Labs AI Summit. Let me say that I do not feel too good about the midterm. But more to the point of inquiry: I'm actually a casual advocate against the use of coffee. That being said, these past two weeks, I've used coffee to strategically energize myself past baseline levels. I feel myself understanding why so many rely on it, as I've understood before, but this time on a more recent affirmation. So I wonder, as we all know that caffeine is scientifically backed in terms of benefits and advantages, I wanted to ask firsthand what the literature had to say about coffee.</p>
							<p>Caffeine consumption, to start, can be 70 t0 76 mg per day worldwide, but "210 to 238 mg/day in the US and Canada, and more than 400mg/person/day in Sweden in Finland". For reference, I found a tall caffe latte at Starbucks is around 75 mg. To think of 400 mg, that's crazy! Is that why they're so progressive and happy and have free healthcare? Now, it's no laughing matter - we may actually considering that caffeine is the X factor in a country's success. After all, I did experience the benefits firsthand of slicing through sloth and feeling the plumage of racing thoughts in class. Caffeine is the most widely used of all psychoactive drugs.</p>
							<p>Caffeine's absorbtion by human intestinal tracts is about 99% after 45 minutes of ingestion. The hydrophobic properties allow transmission through all biological membranes - no placental or blood brain barrier. Peak caffeine in plasma is reached around 15 to 120 minutes after oral ingestion (a somewhat large range of confidence). For doses lower than 10mg/kg, which for me at 70kg is lower than 700mg, well within the average and safe limit, the half life of caffeine is around 2.5 - 4.5 hours. Very useful information for timing and predicting the energy curve from drinking your daily coffee. This is reduced 30 to 50% in smokers, interestingly.</p>
							<p>The way caffeine is postulated to work is this: adenosine is limited to prevent inhibition of excitatory signals. A dose of about 50mg is required to witness "behavioral stimulation". Compared to meth and cocaine, caffeine primarily affects both dopamine receptors. (That begs the question whether or not caffeine is actually just as addictive). My last takeaway from the article is that low doses do seem to facilitate good moods without as much frequency of withdrawal - around 20 - 200mg per day is a good limit for healthy consumption. More than 500mg decreases performance. Low doses of caffeine can also "decrease cerebral brain blood flow", to be compensated with more oxygenation. I've always believed the brain could regulate itself - with enough research I can perhaps to finetune this on a pretty confident level, still maintaining my stand that a daily cup of coffee (if over 200mg) isn't the best of habits.</p>
							<p>October 31, 2017, at the Future Lab AI Summit.</p>
						</li>
					<li>
							<h1>23 Problems in Systems Neuroscience</h1>
							<h2>Computational Neuroscience.<br>
							Sejnowski.<br>2006.</h2>
							<p>Here's another meta-article I want to read early on. It's fairly recent (~10 years, if we will), and can be a good primer on what type of papers to expect in the mainstream progress of neuroscience.</p>
							<p>Let's start off with the quote they use: "As long as brach of science offers an abundace of problems, so long is it alive; a lack of problems foreshadows extinction or the cessation of independent development" (Hilbert 1900). Mutatis mutandis - as the article says, which means "adding more while not affecting the core point" - asks people from Max Planck's conference <i>Problems in Systems Neuroscience 2000</i> to come up with a different field.</p>
							<p>I can only assume these people are foremost, or else I've got my hands on one useless article. Assumption made, we now have the 23 Hilbertian predictions of neuroscience. It's divided into three sections: <ul><li>how have brains evolved, how is the cerebral cortex organized, and how do neurons interact?</li></ul></p>
							<p>So as follows.</p>
							<p>Shall we even understand the fly's brain? Gilles Laurent says small systems, for example small olfactory systems, are not all that 'simple', but use mechanisms that can be generalized. This means the working to understand small systems such as flies can be a worthwhile endeavor, especially to its completion, which I believe in near done in terms of the genome, but perhaps not the network dynamics.</p>
							<p>Can we understand the action of brain in natural environments? Hermann Wagner says that many people work on reduced systems, but evolution may exhibit different results, so its best to observe brains in their pure, unchanged environment in order to learn how they really work.</p>
							<p>Hemisphere dominance of brain function - which functions are lateralized and why? Gunther Ehret says that there can be two explanations: advantages of hemispheral specialization may be significant, having a purpose; and genetic reasons may result in the two regions without a deeper need.</p>
							<p>What is the function of thalamus? S. Murray Sherman says that although the thalamus is reputed to be a dry relay machine, it has more say over state-dependent cortex inputs that we give it credit for. It's a higher order relay, and something that may be critical for "cortico-cortical" communication.</p>
							<p>What is neuronal map? J. Leo van Hemmen says that a map is a neuronal presentation of an outside world, and how can it relate. I'd be interested to read more about this, because isn't everything in a way a mapping if it's already reached our conscious observation?</p>
							<p>What is the role of top-down connections? Jean Buller says that although much of brain processing has been known to come from outside in, AKA bottom-up, there are profound top-down processes occuring that we shan't overlook.</p>
							<p>How fast is neuronal signal transmission? This is a funny one because I've answered a Quora question regarding this and we shall soon see if I shared information correctly (of course I had all reason to be confident in the statistics before). Wulfram Gerstner suggest that neurons being slow is a misconception - for some cases, responses can be immediate.< Some integration delays are negligible so "only axonal delays remain". So, rapid feedback is a possibility.</p>
							<p>What is the origin and functional properties of irregular activity? Carl van Vreeswijk (I guess most people were within a train's range, not bad though) mentions the idea of rate coding. The neurons rate though, can sometimes be inaccurately reflected by the number of spikes fired. The rate is coded "inefficiently". He conclude that "the doubt about the rate code is based on a misunderstanding".	</p>
							<p>Are single cotrical neurons independent or are the obedient members of a huge orchestra? Alright there, Mr. Flowery. I do appreciate the zest, though, which we need. Amiram Grinvald has things to say on this.</p>
							<p>
								What is the other 85% of V1 doing? Kinda salty. Sounds like what my mom used to say but instead of V1, she's talking about how I spent my time. My mom - I mean Bruno A. Olshausen and David J. Field, bring a fair question into fold for one of our most prominent senses. If what they claim is true, then the V1 is a large land yet unexplored, but once thought to be conquered.
							</p	>
							<p>What is the formal computation in early vision? Steven W. Zucker (whom we will call Zuck) says that spiking neuron methods are responsible for computing these calculations which tie in with "polymatrix games".</p>
							<p>How do neurons compute? Carr et al. ask a similar question. Some may think it's pretty straightforward but I like to have this discussion open up.</p>
							<p>How can neural systems computer in the time domain? Aha! This question is something that gets me into a pseudo-philosophical mode. Sophisticated neural representations are likely to have been invented during the course of evolution, says Andreas VM Hertz. And they're down to get to the bottom of this.</p>
							<p>How common are neural codes? David McAlpine (nice) and Alan R. Palmer say that the ability to localize sounds has no explicit representation of spatial environments, yet require auditory space via cues. Neural codes, then, could be a method that is used in many process not yet understood.	</p>
							<p>How does the hearing system perform auditory scene analysis? Georg Klump analyzes how auditory object formation handles "natural soundscapes.</p>
							<p>How does our visual system achieve shift and size invariance? Laurenz Wiskott </p>
							<p>To be continued.</p>
							<p>October 27, in ITP 12:23am</p>
							<p>Shift and size invariant recognition may be solved yet, peering into how the brain constructs invariant representations in general. What is reflected in sensory neocortical activity: External stimuli or what the cortex does with them? Scheich et al. say that evidence suggests map-based patterns depend on specifiic cortical processing functions - thus a broader concept of these functions must be considered.</p>
							<p>To what extent does perception depend upon action? Giacomo Rizzolatti and Vittoria Galllese say that "both action and space perception derive from a preceding motor knowledge based on self-generated actions". What are the projective fields of cotrical neurons? Sejnowski - the editor of the whole article - says that the influence of other neurons needs to be assessed, called the "projective field". He claims this may be the holy grail to unlocking the mysteries of the cerebral cortex. If I had to power to edit, I would say something like that too. Although only if I were anonymous.</p>
							<p>To what extent is the brain reconfigurable? We hear John Reynolds talk about how the brain tunes to associate and discriminate stimuli. Where are the switches on this thing? Hah. The brain needs to have complexs switching circuitry, and this is still based on mechanisms we don't understand. So how do these flows work?</p>
							<p>Do qualia, metaphor, language, and abstract thought emerge from synethesia? VS Ramachandran and Edward Hubbard realize that synesthesia may "illuminate some of the most puzzling aspects of the midn such as the evolution of metaphor and abstract thought". They also look at the neural correlates of "qualia", making this one trip into the deep zone.
							</p>
							<p>What are the neural correlates of consciousness? Francis Crick?! Francis?! You're here! Francis Crick of the Watson and Crick DNA discovery, and Christof Kock, also a big player, are glad to affirm what I've been wondering this whole time and what has led me into the field. So far "no one has put forward any concrete hypothesis that sounds even remotely plausible". Their plan is to leave things aside and focus solely on the NCC (neural correlates of consciousness). I'm definitely giving more of these things a read. Good God I'm pumped now.</p>
							<p>October 28, written in The Tang.</p>
						</li>
					<li>
							<h1>Impact of Windows and Daylight Exposure on Overall Health Quality of Office Workers: A Case-Control Pilot Study</h1>
							<h2>Journal of Clinical Sleep Medicine.<br>Boubekri, Cheung, Reid, et al.<br>2014.</h2>
							<p>For today's paper, I'm doing something that's immediately practical. I'm currently sitting in the 5th floor media area in Bobst library in Manhattan, and the sound of surrounding people is helping me feel on top of it. I found that if I'm constantly working in the quiet among others being quiet, it gives some sort of weird eeriness to it. Granted, quiet focus has its powers - but too much of it probably leaves the brain a bit pruned. The thing is - this room has no windows to the outside. I'm curious what scientific literature has to say about cutting holes in these boxes...</p>
							<p>First, their metrics. They measure "well-being" via sleep quality (qualitative?), light exposure, activity, and sleep-wake patterns. The sample isn't remarkably large, 49, but I could deem it somewhat significant. They measure well-being through a method called Short Form-36, and sleep quality via the Pittsburge Sleep Quality Index (PSQI) - let me look those up right now.</p>
							<p>SF36 is named after it's 36 items. There's 8 scores, summed over sections, which are: vitality, physical functioning, bodily pain, general health perceptions, physical role functioning, emotional role functioning, social role functioning, and mental health. An interesting point: "physical health scores are counted negatively when calculating combined mental health scores and vice versa. In other words, to score highly on mental health it is better to have worse physical health and vice versa." Okay...that may need some evaluation.</p>
							<p>The PSQI is a self-reported questionaire that measures over a 1-month interval. I see no large flaws here opposed to any other self-reported system. Given that, the fact that is it self-reported, we should probably make the experiment in the paper is double-blind...that is, if the people know that they are being tested for quality by not having or having a window, placebo may play a point. That does lead to the question though, in this case, does it matter? If people feel they attained good sleep, e.g. their brain decides the sleep was good on the conscious level, could it be that the sleep was in fact bad and affecting them in ways that go against their feeling (and vice versa)? That's a question beyond this paper which I'd be interested in.</p>
							<p>The paper uses a chi-squared test to compare distributions of their samples, as well as correlation tests via Pearson's. The results?</p>
							<p>No big differences in sleeptime onset, sleep efficiency, or wake after onset, nor on fragmentation. However there were "improvements" via windows in terms of sleeping time (couldn't that just mean they had to spend more time in bed?). Again, I don't really know about the greatness of these results given that the participants could have known what the researchers were testing during the time of experimentation -- but given that their averages are pretty reliably higher for those with windows, I wouldn't say it means to remove your windows. So far, it means to keep your windows if you wish to sleep more and very slightly have better stats than people without windows. In terms of self-reported wellbeing, it's good to have windows - perhaps because there's more data to see in the day that is real and organic? I'd be interested in an experiment that repeats this with a screen in the room passively showing live video of, let's say, a beach or park. We know that sunlight contact can modulate mood, but inside an office there is not really much to say about direct sunlight contact with or without windows. Who knows what are brains are capable of in terms of fooling a screen to have similar effects of a window? For now, though, I'll take a window seat if I can find one. And if I can't, I'll try to replicate one as much as possible.</p>
							<p>October 27 on the fifth floor of Bobst, 3:56pm, making up for October 26th.</p>
						</li>
					<li>
							<h1>Immunology of Dendritic Cells</h1>
							<h2>Annual Review of Immunology.<br>Banchereau, Briere, et al.<br>2000.</h2>
							<p>First off - "dendritic cells (DCs) are antigen-presenting cells with a unique ability to induce primary immune responses". I have to remind myself that <i>antigen</i> specifically means a molecule that can induce immune responses, which are actually attacked directly by antibodies.</p>
							<p>Core responses of our immune system include rapid attention to injury or pathogens and signaling of danger. We list out some terms like phagocytic cells, NK cells, complement and IFNs.</p>
							<p>Let me reprime myself on these before we continue. Phagocytic cells are memorable - they swallow things whole and dissolve them on the inside. Natural killer cells are a white blood cell / lymphocytes that do not require "self" markers, thus can perform without antibodies and "MHC" (major histocompatibility complex, a set of proteins on cell surfaces that judge whether molecules are invited or not). Complements enhance the ability for phagos and antibodies to fulfill their role. IFNs are interferons, which are released specifically in the presence of pathogens - good to note, they don't kill cancer cells but regulate their growth.</p>
							<p>With that jargon out of the way, we can now move past the second sentence of the paper. Adaptive immunity, the paper reads, is the ability to rearrange immunoglobulin genes, allowing diverse sets of antigen-specific clones, a sort of memory. Basically, flexibility like this leads to more robust solutions. Dendritic cells are so interesting in this regard because they are the only guys that can induce direct immune responses, so they could have "immunological memory", something advanced I suppose.</p>
							<p>Now we get to species-specific info...! Mice evidence for myeloid DC development comes from in vitro (outside). Oh boy, and the paper goes on to cite a lot of acronyms. Let me chug through an example: CD8alpha+ means a Cluster of Differentiation (8) alpha chain of a dimer. Humans have four such possibilities for DC development.</p>
							<p>So what's the main insight of the article? Existence of various DC subsets give unique, useful functions such as regulation of responses of B cells (a type of white blood cell). Dendritic cells can also secrete a lot of needed materials at their precursor stage. Also, plasticity. I have a better idea now why these guys are pretty remarkable, and I'll remember it.</p>
							<p>October 26 2017 in Stern basement, making up for October 25th.</p>
						</li>
					<li>
							<h1>Emotion Circuits in the Brain</h1>
							<h2>Annual review of Neuroscience.<br>LeDoux, JE.<br>2000</h2>
							<p>In the top 5 normalized cited neuroscience papers, this article, written by LeDoux of New York University (somewhat my alma mater), isn't afraid to get touchy about the touchy subjects.</p><p>
							We have an explanation of how "emotion research was a victim of the cognitive revolution", claiming that both need to open their minds a little bit more to a other model.
						The limbic system was always associated with emotion, but we can no longer assume so much separation and isolation, the paper claims.</p>
						<p>
							There's lots of talk a lot about the amygdala and all its projections. It's almost 5AM and I just finished making a cross site request forgery project, but I needed to do the paper for the day. I really liked it and I wish to return to write more about it. I read it during my food shift.
						</p>
						<p class='date'>October 24 2017 In Bushwick for the first big "all nighter".</p>
						<p>LeDoux explained the rise of cognitive science due to the impression that "cognitive questions also [were] more tractable than emotional ones". It is easily affirmed that emotion is not a topic most people wish to distill into rudimentary parts - I'd be interested in finding any evidence for an aversion to such research merely on a level where humans refuse to make an incision into something once deemed and still deemed sacred.</p>
						<p>When arguing with my girlfriend, the thread always seems to end that "a relationship shouldn't be based on logic" and, by extension, there should be no decomposition of emotions. This may be a deep-seated aversion in all of us - the reluctancy to view things for what they are and deveil any magic that has been sold by the stories of it.</p>
						<p>The question is whether this is beneficial or instead detrimental in the long run. I believe we can still feel the rush of emotion under a microscope while still feeling them just as enjoyably and profoundly. In fact, I think it opens up more avenues of self-aware experience, which is a prerequisite to a theory of "self-experience" at all (you experience what your cells experience as a sum). So further self-awareness only opens up additional, more recursive continents of emotional settlement.</p>
						<p>However, I digress, but as an "offer of relevant digression" from which I will now abbreviate as ORDing. Because I do agree that reading primary sources are the most authentic way to learn if available, I wish not only to summarize a piece, but to add my own personal character to it - speaking of emotion and human magic.</p>
						<p>LeDoux continues to explain the Pavlovian circuit, which I assume many if any readers will know, is how fear is bred in us, for example, how a loud noise pretenses our sweat. The takeaway from his piece is the power of the plastic amygdala, being able to condition emotional responses for distinct external events. At the end of the day, the paper serves as a great recollection of the cognitive-emotional schism in neuroscience, whose fallout we can still feel washed about to this day.</p>
						<p class='date'>October 26, 2017, in the basement of Stern.</p>
					</li>
					<li>
						<h1>At the Leading Front of Neuroscience: A Bibliometric Study of the 100 Most-Cited Articles</h1>
						<h2>Frontiers in Human Neuroscience.<br>Andy Yeung, Tazuko Goto, and W. Leung.<br> 21 July 2017. </h2>
						<span>
							<p>
								For my first lip-smacking appetizer I'm cutting through the drab and going straight for the meta: an analysis of the 100 most cited neuroscience articles in recorded history.
							</p>
							<p>
								Two of these guys are from University of Hong Kong. They're publishing this review due to "lack of...a comprehensive review of major research topics in neuroscience"<span class="cite tooltip">[1]</span>. They are sure to mention the already published reviews of top articles in subfields of neuroscience, distinguishing those from a more broad evaluation they are attempting.
							</p>
							<p>
								What's their approach? They gathered data from a service called Web of Science, which provides metrics of published science from 1945 (what a time). Some columns in this data include: publication year, journal impact factor per year, and normalized citation count (defined as first 10 years' citations / count of all neuro publications for those 10 years).
							</p>
							<p>
								Bradford's law is mentioned as a significant consideration in their measurements. I've met one Bradford in my life and he is a pretty cool guy, so I was curious to see what this other Bradford had to offer. So I looked up the law by itself: Samuel C. Bradford's 1934 "law" estimates how searching for references in science journals has diminishing returns - in other words, most articles a researcher wants to peruse will be in a few journals, similar to the Pareto Principle and Zipf's law. Supposedly, "very rarely" will  researchers need to go outside this set. It leads me to question if this approach is necessarily positive, considering the story of neural net papers that lurked under the radar until computing power became sufficient enough for the method to gain traction (likely more on that in a future reading). Notably, Bradford's law has a three partition prediction that in which the distributions will have ratios 1:n:n^2. In the end, they concluded that citations did not follow Bradford's law. Props for hypothesizing though.
								So, the main point, what were some of the most cited articles in this article? Keep in mind that there were two ranking systems: rank A, which bases off of normalized citation counts, and Rank B, which looks at absolute number of citations. Let's look at Rank A, which implies relative impact per time period to allow more recent contenders to come into the fold.
							</p>
							<p>
								1984's <i>Magnesium gates glutamate-activated channels in mouse central neurons</i> in Nature tops the list, followed by 1988's <i>Glutamate neurotoxicity and diseases of the nervous-system</i> singly authored by D. W. Choi. Some more recent ones (Y2K and after) include <i>Immunobiology of dendritic cells</i>, <i>The 2007 WHO classification of tumours of the central nervous system</i>, <i>Central nervous system control of food intake</i>, <i>An integrative theory of prefrontal cortex function</i>, <i>Complex Brain networks: graph theoretical analysis of structural and function systems</i>, <i>Emotion circuits in the brain</i>.
							</p>
							<p>
								This list will be a perfect jumping off point for this "paper a day" project, which I will call "Brain States". I'll try to cover the core material and venture into the latest publications both in neuroscience and in the fields of perception, computational learning, and other large breakthroughs.
							</p>
							<p>
								There are surely some gems out there with low citation counts, and I will give them due respect down the line - first training on those at the top, perhaps capturing some trends that inject biased popularity - and thus allowing a complentary eye for any counterintuitive secrets in the woodwork.
							</p>
							<p>
								For now, this record is for my own journaling, whose raw HTML I will upload to Github as a ledger. If you do happen to come across this, thank you for reading the first and most primitive installment of Brain States.
							</p>
							<p>October 23, 2017 4:25pm New York, New York right before my Programming Languages class.</p>
					</li>
					<li>
						<h1>Reasons to use Phoenix instead of Rail</h1>11702526
					</li>

					<li>
						<h1>Ask HN: How to become the first result of a Google search for a name?</h1>
						<p>This doesn't apply to me because I happen to already be the first search result for my name, happening to have a random internet presence since my low teens. Nonetheless, what is suggested is that the site becomes a destination, having all roads lead there. In fact, one could change their name into something greatly unique, like a hex hash a975c295ddeab5b1a5323df92f61c4cc9fc88207. A low bounce rate (lots of time on page) can help rankings. Otherwise, no simple way, as things have become a bit more nuanced since the age of PageRank.</p>
						<p>Nov 13 (Nov 26)</p>
					</li>
					<li>
						<h1>How (and why) to create a good validation set</h1>
						<p>This is good. This addresses the problem of overfitting, something I constantly think about not only in terms of machine learning but in school systems and education. How do we make sure data being trained on can generalize well? At some point, a machine may realize that data does not generalize and stop working so hard to train on it - but it is also aware to get back in the game if that becomes too big of an excuse. sklearn, a python library, offers a train-test-split pipelines. Validation sets are essential to prepare yourself for good production code the first time around.</p>
						<p>Nov 12 (Nov 26)</p>
					</li>
					<li>
						<h1>What if consciousness is not what drives the human mind?</h1>
						<p>"Most experts [apparently] believe that [it] can be divided into two parts: the experience of consciousness (or personal awareness), and the content of consciousness, which include things such as thoughts, beliefs, sensations, perceptions, intentions, memories and emotions". Interesting. The paper cited in Frontiers of Psychology says that consciousness is not the source of thoughts. I thought that already well-recognized? Although, I see that many can still feel that they are everything they can feel, and nothing below. Thoughts have always been firing before we could recognize them - which is why design is really important in life, practically, objectively, and personally. Even knowing this does not save us from the lack of addressing it, as I know.</p>
						<p>Nov 11 (Nov 26)</p>
					</li>
					<li>
						<h1>Bitcoin Blows Past $9000</h1>
						<p>This story is legitimately filtered in Gizmodo under "Bubble What Bubble". So, what's the worst that can happen? A crash, though some money may go a long way. Once I return this Winter I may reinvest (need to renew my state ID in person to regain access to Coinbase). I joined for fun during the Dogecoin train maybe 4 years ago. In the case, the price may have doubled - I don't quite remember what I bought on coinbase, or if my harddrive has any wallets on it at home. But this train seems to be already moving...if it takes off like a rocket (and reaches escape velocity) then we'll just consider that a interesting time to be alive, and focus on other things and watch those who got lucky spend their windfalls. The difficult part is to hold or to keep, as a burst would be fun to see. Perhaps governments will eventually adopt. If so though, I don't think they'd allow this massive value expansion to persist.</p>
						<p>Nov 10 (Nov 26)</p>
					</li>
					<li>
						<h1>Firefox will soon flag sites that have been hacked</h1>
						<p>Ever since the release of Firefox Quantum (which I suspect wholly by feeling that it is simply a rebranding of Firefox), a slew of features and impressive benchmarks have come out. One, apparently, is now it will warn if a site has "suffered a data breach". The only loser here are the hackers and sites that seek to get away with questionable security. As for how fast the response time is to fresh hacks, I'd be curious to see.</p>
						<p>Nov 9 (Nov 27)</p>
					</li>
					<li>
						<h1>The beginning of the end for the copper wire</h1>
						<p>FCC voted last Thursday to allow AT(and)T and Verizon to more easily tear down old copper wiring. This means DSL offerings will decrease in number, slating a whole shelf of lower price internet away, also without voice option or 911 access in (some) rural areas. Beseides the moral implications, it's news to consider.</p>
						<p>Nov 8 (Nov 26)</p>
					</li>
					<li>
						<h1>Can anyone make money on the moon?</h1>
						<p>Well I've exhausted that list of shortest papers ever. Now I'm reaching in the cookie jar a bit and expediting through thought-provoking articles, which I would usually read anyway, but not include here. Indeed, I may make a branch for them.</p>
						<p>Next year the company Moon Express, 30 employees strong, will be the first private entity to put a robolander on the moon. They may win the $20 mil X prize hosted by Google. There is something called the Outer Space treaty, started 50 years ago. It enumerates space etiquette for countries, preventing the nuclear threats from rising high into the atmosphere.</p>
						<p>But now it may be a "threat to entrepreneurs". Space entrepreneurs that is. Officially called the 'Treaty on Principles Governing the Activites of States in the Exploration and Use of Outer Space', it says that space will be used for 'peaceful' purposes. Nothing quite like the dewfall.</p>
						<p>Moon Express has spent about a year talking to the FAA to create a temporary patch, using its authority to let the rockets fly up. Planetary Resources is yet another company, this one with a goal to mine asteroids. A key sentence to note, extendable to many a wistful thing: "While the psychological barrier to mining asteroids is high, the actual financial and technological barriers are far lower".</p>
						<p>Mr. Shneider, PM of Luxembourg, was "wondering what [Peter Warden, director of NASA Ames] might have smoked". But over time, the idea became more normalized and logical, warmed up to.</p>
						<p>So, Congress is revising the Outer Space treating this year, or at least reassessing it. A bill has been sent to the full House.</p>
						<p>I wrote about this in an article a couple years ago, the exact same analogy: Dr. Richards compared this moment to "the 19th century California Gold Rush".</p>
						<p>Nov 7 (Nov 26)</p>
					</li>
					<li>
						<h1>Highter Taxa: Reply to cartmill</h1>
						<p>Something to with taxonomy and museums.</p>
						<p>Nov 6 (Nov 26)</p>
					</li>
					<li>
						<h1>Is the sequence of earthquakes in southern California with afterschocks remove, Poissonian?</h1>
						<p>Yes. Poissonions.</p>
						<p>Nov 5 (Nov 26)</p>
					</li>
					<li>
						<h1>Guaranteed Margins for LQG Regulators</h1>
						<p>"There are none.</p>
						<p>Nov 5 (Nov 26)</p>
					</li>
					<li>
						<h1>Can apparent superlimunal neutrino speeds be explained as a quantum weak measurement?</h1>
						<p>Probably not.</p>
						<p>Nov 4 (Nov 26)</p>
					</li>
					<li>
						<h1>Interlude</h1>
						<p>I can learn a lot of stuff but without maintenance forget a lot of stuff...so here's to consistent practicing...a forever emptying bucket of knowledge, with pieces the size of sand and a hole the size of the human brain.</p>
					</li>
					<li>
						<h1>A comprehensive overview of chemical-free consumer products</h1>
						<p>Chemical-free products are very low in supply.</p>
						<p>Nov 3 (Nov 26)</p>
					</li>
					<li>
						<h1>The Unsuccessful Self-Treatment of a Case of "Writer's Block"</h1>
						<p>This counts, and it was peer reviewed.</p>
						<p>Nov 2 (Nov 26)</p>
					</li>
					<li>
						<h1>Can n^2+1 unit equilateral triangles cover an equilateral triangle of side > n, say n + eps?</h1>
						<p>Yes?</p>
						<p>Nov 1 (Nov 26)</p>
					</li>
					<li>
						<h1>Counterexample to Euler's Conjecture of Like Powers</h1>
						<p>Catchup for 27 days. No excuses let's do it. First, we read, and write, and understand, Then at the end of the week we capend the readings both for reinforcement and for extra details such as year of publication, journal, etc.</p>
						<p>"A direct search on the CDC 6600 yeildded 27^5 + 84^5 + 110^5 + 133^5 = 144^5". This goes against Euler's conjecture that at least n nth powers are required to sum to an nth power, n > 2. Nice!</p>
						<p>Oct 31 (Nov 26)</p>

					</li>
					
					</ul>
				</div>

							<div id="pnum" style="text-align: center;">
				<a href="index.html" style="color:salmon">UP</a>
			</div>


				<div id="afferents">
					The approach is simple. At least a paper a day (or the attempt) will foster an n-paper leg up per year. The more papers one reads, the less torturous and intimidating the thickness of scientific jargon becomes, and the more natural and immediate the understanding of the content seems. Additionally, it maintains the integrity and checks the status of the current publishing sphere, which we all know is the best we have, but isn't perfect. It is science from the human perspective patrolled by science in the absolute one. There's no claiming to be an expert in the field regarding every paper read, but we will admit the believe that reading papers that don't necessarily have to do with a PhD area or a silo of a person's specialized field does have its big picture pluses, such as incorporating diverse phenomenon as well as connecting a wider survey on each field's linguistics. At the end of the day, I'm just trying to get a mastery of what we humans have up until this point, so that I can perhaps add on a leaf or two to the home tree.
					<h2>The Inputs</h2>
					<h4>Items from this list will move up into the processed area once read.</h4>
					<p>See the importance of keeping up with literature <a style="color:gray" href="http://www.sciencemag.org/careers/2016/11/how-keep-scientific-literature">here</a>.</p>
					<ul>
						
						<li>At the Leading Front of Neuroscience: A Bibliometric Study of the 100 Most-Cited Articles
							<p>Frontiers in Human Neuroscience. 2017. Andy Yeung, Tazuko Goto, and W. Leung. <br>Processed Oct 23 2017<p>
							</li>
							<li>
								Immunobiology of dendritic cells.
								<p>Annual Review of Immunology. 2000. Banchereau, Briere, Palucka, et al.</p>
							</li>
							<li>
								Emotion circuits in the brain.
								<p>Annual Review of Neuroscience. 2000. LeDoux, JE.</p>
							</li>
							<li>Something to do with collections.</li>
							<li>Something to do with laziness.</li>
							<li>Something to do with understanding.</li>
							<li>Something to do with learning math.</li>
							<li>Something to do with wittines.s</li>
							<li>Something to do with procrastination.</li>
							<li>Something to do with probability representation.</li>
							<li>Something to do with tipping??</li>
						</ul>
					</div>
					
				</div>
			</body>
		</html>